import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title('AI-–ø—Ä–æ–≥–Ω–æ–∑ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ')

# –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
st.subheader('–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞—Ä—Ç–∏—Ä—ã:')

city = st.selectbox('–ì–æ—Ä–æ–¥', ['Almaty', 'Astana', 'Shymkent', 'Karaganda'])
rooms = st.number_input('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç', min_value=1, max_value=5, value=2)
location = st.selectbox('–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ', ['Center', 'Outskirts', 'Near Center'])
area = st.number_input('–ü–ª–æ—â–∞–¥—å (–≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∞—Ö)', min_value=50, max_value=500, value=100)
floor = st.number_input('–≠—Ç–∞–∂', min_value=1, max_value=25, value=3)
status = st.selectbox('–°—Ç–∞—Ç—É—Å –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏', ['Ready to Move', 'Under Construction'])
floor_quality = st.selectbox('–ö–∞—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–∞', ['Normal', 'Not Very Good', 'Good'])

# Label Encoding
le_location = LabelEncoder().fit(['Center', 'Outskirts', 'Near Center'])
le_status = LabelEncoder().fit(['Ready to Move', 'Under Construction'])
le_city = LabelEncoder().fit(['Almaty', 'Astana', 'Shymkent', 'Karaganda'])
le_floor_quality = LabelEncoder().fit(['Normal', 'Not Very Good', 'Good'])

location_encoded = le_location.transform([location])[0]
status_encoded = le_status.transform([status])[0]
city_encoded = le_city.transform([city])[0]
floor_quality_encoded = le_floor_quality.transform([floor_quality])[0]

input_data = np.array([[rooms, location_encoded, area, floor, floor_quality_encoded, status_encoded, city_encoded]])

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
df = pd.read_csv('real_estate_database_with_floor.csv')
df['Location'] = le_location.transform(df['Location'])
df['Status'] = le_status.transform(df['Status'])
df['Floor Quality'] = le_floor_quality.transform(df['Floor Quality'])
df['City'] = le_city.transform(df['City'])

X = df[['Rooms', 'Location', 'Area (sqm)', 'Floor', 'Floor Quality', 'Status', 'City']]
y = df['Price (in tenge)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –ú–æ–¥–µ–ª–∏ Supervised Learning
models = {
    "Linear Regression": LinearRegression(),
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Naive Bayes": GaussianNB(),
    "K-Nearest Neighbor": KNeighborsRegressor(),
    "SVM": SVR(),
    "Gradient Boosting": GradientBoostingRegressor()
}

st.subheader("üìå –ê–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (—á–∞—Å—Ç—å A):")

for name, model in models.items():
    if st.button(name):
        try:
            model.fit(X_train, y_train)
            prediction = model.predict(input_data)[0]
            mse = mean_squared_error(y_test, model.predict(X_test))
            st.success(f"–ú–æ–¥–µ–ª—å: {name}")
            st.write(f"üîπ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: **{prediction:,.2f} ‚Ç∏**")
            # st.write(f"üìâ –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE): {mse:,.2f}")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª–∏ {name}: {e}")

st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π")

import matplotlib.pyplot as plt

# === –ñ–µ–ª–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===
st.subheader("üí∏ –ñ–µ–ª–∞–µ–º–∞—è —Ü–µ–Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—ã (–ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é)")

desired_price = st.number_input(
    "–í–≤–µ–¥–∏—Ç–µ –∂–µ–ª–∞–µ–º—É—é —Ü–µ–Ω—É –ø—Ä–æ–¥–∞–∂–∏ –∫–≤–∞—Ä—Ç–∏—Ä—ã (–≤ —Ç–µ–Ω–≥–µ):",
    min_value=1000000,
    max_value=200000000,
    value=30000000,
    step=1000000
)

if st.button("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Å –∂–µ–ª–∞–µ–º–æ–π —Ü–µ–Ω–æ–π"):
    all_models = {
        "Linear Regression": LinearRegression(),
        "Logistic Regression": LogisticRegression(),
        "Decision Tree": DecisionTreeRegressor(),
        "Random Forest": RandomForestRegressor(),
        "Naive Bayes": GaussianNB(),
        "K-Nearest Neighbor": KNeighborsRegressor(),
        "SVM": SVR(),
        "Gradient Boosting": GradientBoostingRegressor()
    }

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.axhline(y=desired_price, color='red', linestyle='--', label="–ñ–µ–ª–∞–µ–º–∞—è —Ü–µ–Ω–∞")

    user_preds = {}

    for i, (name, model) in enumerate(all_models.items()):
        try:
            model.fit(X_train, y_train)
            user_price = model.predict(input_data)[0]
            user_preds[name] = user_price

            # –†–∏—Å—É–µ–º –∑–≤—ë–∑–¥–æ—á–∫—É
            ax.scatter(i, user_price, marker='*', s=250, label=name, edgecolors='black')
            ax.text(i, user_price + 500000, f"{int(user_price):,}", ha='center', fontsize=9)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è {name} ‚Äî –æ—à–∏–±–∫–∞: {e}")

    ax.set_xticks(range(len(user_preds)))
    ax.set_xticklabels(user_preds.keys(), rotation=45, ha='right')
    ax.set_ylabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ (—Ç–µ–Ω–≥–µ)")
    ax.set_title("üìà –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ vs –í–∞—à–∞ –∂–µ–ª–∞–µ–º–∞—è —Ü–µ–Ω–∞")
    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
    st.pyplot(fig)

    # –ö—Ç–æ –±–ª–∏–∂–µ –∫ –∂–µ–ª–∞–µ–º–æ–π —Ü–µ–Ω–µ
    diffs = {name: abs(desired_price - price) for name, price in user_preds.items()}
    closest_model = min(diffs, key=diffs.get)
    closest_diff = diffs[closest_model]

    st.markdown("---")
    st.markdown(f"üéØ **–ë–ª–∏–∂–µ –≤—Å–µ–≥–æ –∫ –≤–∞—à–µ–π –∂–µ–ª–∞–µ–º–æ–π —Ü–µ–Ω–µ**: `{closest_model}` "
                f"(–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: **{closest_diff:,.0f} ‚Ç∏**)")


# ========== PART B ==========
st.subheader("üß† –ê–ª–≥–æ—Ä–∏—Ç–º—ã –±–µ–∑ —É—á–∏—Ç–µ–ª—è (—á–∞—Å—Ç—å B):")

# K-Means
if st.button("K-Means Clustering"):
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(X)
    cluster = kmeans.predict(input_data)[0]
    st.success(f"K-Means –æ–ø—Ä–µ–¥–µ–ª–∏–ª: –∫–≤–∞—Ä—Ç–∏—Ä–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫–ª–∞—Å—Ç–µ—Ä—É ‚Ññ{cluster + 1}")

# PCA
if st.button("PCA (–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)"):
    pca = PCA(n_components=2)
    components = pca.fit_transform(X)
    user_transformed = pca.transform(input_data)
    st.success("PCA-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
    st.write(f"üìâ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1: {user_transformed[0][0]:.2f}")
    st.write(f"üìâ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2: {user_transformed[0][1]:.2f}")

# –ú–∞–ø–ø–∏–Ω–≥ –∑–Ω–∞—á–µ–Ω–∏–π –æ–±—Ä–∞—Ç–Ω–æ –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
city_map = dict(zip(le_city.transform(le_city.classes_), le_city.classes_))
status_map = dict(zip(le_status.transform(le_status.classes_), le_status.classes_))
rooms_map = {str(i): f"{i} –∫–æ–º–Ω–∞—Ç" for i in range(1, 6)}

combined_map = {
    **{str(k): f"–ì–æ—Ä–æ–¥ = {v}" for k, v in city_map.items()},
    **{str(k): f"–°—Ç–∞—Ç—É—Å = {v}" for k, v in status_map.items()},
    **rooms_map
}

# Apriori –∫–Ω–æ–ø–∫–∞
if st.button("Apriori (–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏)"):
    df_apriori = df[['City', 'Rooms', 'Status']].astype(str)
    transactions = df_apriori.values.tolist()

    te = TransactionEncoder()
    te_data = te.fit_transform(transactions)
    df_trans = pd.DataFrame(te_data, columns=te.columns_)

    freq_items = apriori(df_trans, min_support=0.05, use_colnames=True)
    rules = association_rules(freq_items, metric="lift", min_threshold=1)

    st.subheader("üìä –ß–∞—Å—Ç—ã–µ –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏:")

    if not rules.empty:
        for i, row in rules.head(3).iterrows():
            antecedents = [combined_map.get(item, item) for item in row['antecedents']]
            consequents = [combined_map.get(item, item) for item in row['consequents']]
            st.write(f"‚úÖ –ï—Å–ª–∏ {' –∏ '.join(antecedents)}, —Ç–æ –æ–±—ã—á–Ω–æ {' –∏ '.join(consequents)} "
                     f"(–ø—Ä–∞–≤–∏–ª–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ {row['support']*100:.0f}% –∑–∞–ø–∏—Å–µ–π)")
    else:
        st.warning("–ü—Ä–∞–≤–∏–ª–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")


if st.button("üìà –ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (PCA + KMeans)"):
    # PCA
    pca = PCA(n_components=2)
    components = pca.fit_transform(X)

    # KMeans
    kmeans = KMeans(n_clusters=3, random_state=42)
    labels = kmeans.fit_predict(X)
    centers = kmeans.cluster_centers_
    centers_2d = pca.transform(centers)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_pca = pca.transform(input_data)

    # –ì—Ä–∞—Ñ–∏–∫
    fig, ax = plt.subplots()
    scatter = ax.scatter(components[:, 0], components[:, 1], c=labels, cmap='viridis', alpha=0.6, label='–ö–≤–∞—Ä—Ç–∏—Ä—ã')
    ax.scatter(centers_2d[:, 0], centers_2d[:, 1], c='red', marker='X', s=200, label='–¶–µ–Ω—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
    ax.scatter(user_pca[0][0], user_pca[0][1], c='black', marker='*', s=200, label='–í–∞—à–∞ –∫–≤–∞—Ä—Ç–∏—Ä–∞')

    ax.set_title('PCA + K-Means –ö–ª–∞—Å—Ç–µ—Ä—ã')
    ax.set_xlabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
    ax.set_ylabel('–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
    ax.legend()
    st.pyplot(fig)